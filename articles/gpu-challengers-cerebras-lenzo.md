---
title: "GPU一強時代に挑む2つのアプローチ（Cerebras vs Lenzo）"
emoji: "🔥"
type: "tech"
topics: ["ai", "半導体", "cerebras", "lenzo", "cuda"]
published: false
---

## はじめに

> 業務自動化Pythonエンジニア。バイブコーディング歴1年 ≒ エンジニア歴。

### なぜGPU以外に注目？

AI半導体といえばNVIDIA。GPU一強時代。

でも最近、別のアプローチで挑む企業が気になっている。

- **Cerebras**：ウェーハ丸ごと1チップにする狂気のアプローチ
- **Lenzo**：日本発、データを動かさない効率重視のアプローチ

両社ともNVIDIAと正面衝突せず、違う山を登ろうとしている。

## CUDAという壁

### NVIDIAの本当の強さ

NVIDIAが強いのは、GPUの性能だけじゃない。

**CUDA**というソフトウェアエコシステムが本当の強み。

- TensorFlow、PyTorchなど主要フレームワークがCUDA前提
- 開発者の学習コスト・移行コストが高い
- 「CUDAで動く」というだけで選ばれる

つまり、いくらハードウェアが優れていても、CUDAエコシステムに乗れないと採用されにくい。

### 挑戦者たちの戦略

だから挑戦者たちは「CUDA互換を追求する」か「別の山を登る」かを選ぶ必要がある。

| 戦略 | メリット | デメリット |
|------|----------|------------|
| CUDA互換 | 既存コードがそのまま動く | NVIDIAの土俵で戦うことになる |
| 別の山 | 独自の強みを活かせる | エコシステム構築が必要 |

CerebrasもLenzoも「別の山を登る」戦略を取っている。

## Cerebras：物量で勝負

### ウェーハ丸ごと1チップ

普通、半導体はウェーハから小さく切り出してチップを作る。

Cerebrasは**ウェーハ全体を1つの巨大チップにする**。

> NVIDIA　なぜお前が　至高の領域に踏み入れないのか　教えてやろう
> 小さく刻むからだ　繋がねばならぬからだ　汎用 GPU だからだ

参考: [NVIDIA を超える AI チップ Cerebras の全貌 - Zenn](https://zenn.dev/because02and/articles/cerebras-overview)

### スペック

WSE-3（最新世代）：

- 4兆トランジスタ
- 900,000 AIコア
- 125ペタフロップス
- NVIDIA H100の**56倍**のサイズ

### 狙い

**超大規模モデルの学習**に特化。

GPUを何百台も束ねる複雑さを、1チップで解決する。データセンター向け。

## Lenzo：効率で勝負

### データを動かさない

AI計算では、演算そのものよりも**データ移動**に多くの電力が消費される。

GPUはメモリアクセスが頻繁に発生する構造。推論用途ではオーバースペックになりやすい。

Lenzoは**CGLA（Coarse-Grained Linear Array）** というアーキテクチャを採用。

- 演算ユニット（PE）の近くにデータを配置
- 長距離メモリアクセスを回避
- 「データを動かさない」ことで電力効率を向上

### 狙い

**推論特化・省電力**。

- エッジデバイス
- 電力制約の厳しい環境
- 用途が明確に決まったシステム

GPUがやりすぎな場所で、別の選択肢として成立する。

参考: [日本発AI半導体スタートアップ "Lenzo" - note](https://note.com/neo_tech_world/n/n547457d07c11)

## 比較

| 項目 | Cerebras WSE | Lenzo CGLA |
|------|-------------|------------|
| アプローチ | 物理的スケール（巨大化） | 論理的効率（データフロー） |
| 目標 | 超大規模モデルの学習 | 推論特化・電力効率 |
| メモリ戦略 | 巨大オンチップSRAM | PE近傍にデータ配置 |
| ターゲット | データセンター・HPC | エッジ・電力制約環境 |
| CUDAとの関係 | 独自言語、ドメイン特化コンパイラ | CUDA互換を追求せず |

### 本質的な違い

**Cerebras**: 「チップを巨大にすることで、GPUを束ねる複雑さを排除する」

**Lenzo**: 「データを動かさないことで、無駄な電力消費を根本から減らす」

## AI半導体マップ

CerebrasとLenzo以外にも、GPU一強に挑むプレイヤーがいる。

```
【汎用GPU】
  NVIDIA H100/B200 - 学習も推論も何でも、CUDAエコシステム

【クラウド専用ASIC】
  Google TPU     - 学習特化、Google専用
  AWS Trainium   - 学習特化、AWS専用（Claudeもここで動いてる）
  AWS Inferentia - 推論特化、AWS専用

【スタートアップ・特化型】
  Cerebras WSE - 超大規模学習、ウェーハ丸ごと
  Groq LPU     - 推論特化、爆速（NVIDIAが200億ドルで買収）
  Lenzo CGLA   - 推論特化、省電力
```

### ざっくり使い分け

| 用途 | 選択肢 |
|------|--------|
| 何でもやりたい | NVIDIA GPU |
| 超大規模モデルの学習 | Cerebras、Google TPU、AWS Trainium |
| 爆速で推論したい | Groq LPU |
| 省電力で推論し続けたい | Lenzo CGLA、AWS Inferentia |

### Groqについて補足

Groq LPUは「決定論的アーキテクチャ」で、GPUの2〜10倍のトークン生成速度を実現。

NVIDIAが2025年12月に200億ドルで買収した。「推論で勝てない」と判断して技術ごと買ったということ。

ちなみに、X社の「Grok」とは全くの別物（名前が似てるだけ）。

## まとめ

GPU一強時代に、別のアプローチで挑む企業がいる。

- **Cerebras**：物量で勝負。ウェーハ丸ごと1チップ。
- **Lenzo**：効率で勝負。データを動かさない。

両社ともCUDAの壁を避けて、別の山を登っている。

NVIDIAの代わりになるわけじゃない。でも「GPUがオーバースペックな場所」で、選択肢が増えるのは良いこと。

AI半導体の世界、面白くなってきた。

## 参考リンク

- [NVIDIA を超える AI チップ Cerebras の全貌 - Zenn](https://zenn.dev/because02and/articles/cerebras-overview)
- [日本発AI半導体スタートアップ "Lenzo" - note](https://note.com/neo_tech_world/n/n547457d07c11)
- [Cerebras 公式](https://www.cerebras.ai/)
