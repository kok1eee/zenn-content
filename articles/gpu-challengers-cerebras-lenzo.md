---
title: "LFM 2.5からAI半導体の世界を覗いてみた"
emoji: "🔥"
type: "tech"
topics: ["ai", "半導体", "cerebras", "lenzo", "cuda"]
published: false
---

## はじめに

> 業務自動化Pythonエンジニア。バイブコーディング歴1年 ≒ エンジニア歴。

### きっかけ：LFM 2.5を試した

先日、Liquid AIの超小型LLM「LFM 2.5-JP」を試した。

前の記事では「続きをどうぞ」で壊れてダメダメだったけど、他の7BモデルのLLMと比べたら確かに日本語がめちゃめちゃ綺麗だった。

色々調整したらまた面白そう。（これはまた今度）

### Lenzoの話を聞いて「何もわかってない」と気づいた

そこから色々流れてくる情報の中で、**Lenzo**という日本企業の話を初めて聞いた。

この話を聞いて、AI半導体について全く理解していないことに気づいた。

私の理解：
- **GPU**：言わずもがな、並列処理に強い
- **NPU**：最近聞かないけど、ローカルLLMに強い？
- **TPU**：Googleが作ったすごいやつ
- **WSE**：Cerebrasのやつ。去年から推してる
- **Lenzo**：...？全くわからない

### AIと一緒に調べてみた

というわけで、Claude先生と一緒にAI半導体の世界を調べてみた。

学んだことをまとめていく。

## CUDAという壁

### NVIDIAの本当の強さ

NVIDIAが強いのは、GPUの性能だけじゃない。

**CUDA**というソフトウェアエコシステムが本当の強み。

- TensorFlow、PyTorchなど主要フレームワークがCUDA前提
- 開発者の学習コスト・移行コストが高い
- 「CUDAで動く」というだけで選ばれる

つまり、いくらハードウェアが優れていても、CUDAエコシステムに乗れないと採用されにくい。

### 挑戦者たちの戦略

だから挑戦者たちは「CUDA互換を追求する」か「別の山を登る」かを選ぶ必要がある。

| 戦略 | メリット | デメリット |
|------|----------|------------|
| CUDA互換 | 既存コードがそのまま動く | NVIDIAの土俵で戦うことになる |
| 別の山 | 独自の強みを活かせる | エコシステム構築が必要 |

CerebrasもLenzoも「別の山を登る」戦略を取っている。

## Cerebras：物量で勝負

### ウェーハ丸ごと1チップ

普通、半導体はウェーハから小さく切り出してチップを作る。

Cerebrasは**ウェーハ全体を1つの巨大チップにする**。

> NVIDIA　なぜお前が　至高の領域に踏み入れないのか　教えてやろう
> 小さく刻むからだ　繋がねばならぬからだ　汎用 GPU だからだ

参考: [NVIDIA を超える AI チップ Cerebras の全貌 - Zenn](https://zenn.dev/because02and/articles/cerebras-overview)

### スペック

WSE-3（最新世代）：

- 4兆トランジスタ
- 900,000 AIコア
- 125ペタフロップス
- NVIDIA H100の**56倍**のサイズ

### 狙い

**超大規模モデルの学習**に特化。

GPUを何百台も束ねる複雑さを、1チップで解決する。データセンター向け。

## Lenzo：効率で勝負

### データを動かさない

AI計算では、演算そのものよりも**データ移動**に多くの電力が消費される。

GPUはメモリアクセスが頻繁に発生する構造。推論用途ではオーバースペックになりやすい。

Lenzoは**CGLA（Coarse-Grained Linear Array）** というアーキテクチャを採用。

- 演算ユニット（PE）の近くにデータを配置
- 長距離メモリアクセスを回避
- 「データを動かさない」ことで電力効率を向上

### 狙い

**推論特化・省電力**。

- エッジデバイス
- 電力制約の厳しい環境
- 用途が明確に決まったシステム

GPUがやりすぎな場所で、別の選択肢として成立する。

参考: [日本発AI半導体スタートアップ "Lenzo" - note](https://note.com/neo_tech_world/n/n547457d07c11)

## 気づき1：チップの種類

調べていくと、チップにも種類があることがわかった。

```
柔軟性 高い ←――――――――――――――→ 低い
           GPU    CGRA    CGLA    ASIC

効率   低い ←――――――――――――――→ 高い
           GPU    CGRA    CGLA    ASIC
```

- **GPU**：何でもできる（汎用）
- **CGRA**：粗粒度で再構成可能（2次元グリッド）
- **CGLA**：線形配列でシンプル（Lenzoが採用）
- **ASIC**：1つの用途に完全特化（Google TPUなど）

Lenzoは「ある程度の柔軟性を保ちながら、効率を追求する」バランスを狙っている。

## 気づき2：学習特化と推論特化

AI半導体には**学習特化**と**推論特化**がある。

| 種類 | 特徴 | 例 |
|------|------|-----|
| 学習特化 | 大量データで重みを更新 | Cerebras WSE、AWS Trainium |
| 推論特化 | 学習済みモデルで予測 | Lenzo CGLA、AWS Inferentia、Groq LPU |

Cerebrasは学習、Lenzoは推論。そもそも土俵が違った。

## Cerebras vs Lenzo

| 項目 | Cerebras WSE | Lenzo CGLA |
|------|-------------|------------|
| アプローチ | 物理的スケール（巨大化） | 論理的効率（データフロー） |
| 目標 | 超大規模モデルの学習 | 推論特化・電力効率 |
| メモリ戦略 | 巨大オンチップSRAM | PE近傍にデータ配置 |
| ターゲット | データセンター・HPC | エッジ・電力制約環境 |

### 本質的な違い

**Cerebras**: 「チップを巨大にすることで、GPUを束ねる複雑さを排除する」

**Lenzo**: 「データを動かさないことで、無駄な電力消費を根本から減らす」

## AI半導体マップ

CerebrasとLenzo以外にも、GPU一強に挑むプレイヤーがいる。

```
【汎用GPU】
  NVIDIA H100/B200 - 学習も推論も何でも、CUDAエコシステム

【クラウド専用ASIC】
  Google TPU     - 学習特化、Google専用
  AWS Trainium   - 学習特化、AWS専用（Claudeもここで動いてる）
  AWS Inferentia - 推論特化、AWS専用

【スタートアップ・特化型】
  Cerebras WSE - 超大規模学習、ウェーハ丸ごと
  Groq LPU     - 推論特化、爆速（NVIDIAが200億ドルで買収）
  Lenzo CGLA   - 推論特化、省電力

【エッジ・組み込み】
  NPU - スマホやPCに内蔵。Apple Neural Engine、Qualcomm NPUなど
```

NPU、最近聞かないどころか今やどこにでも入ってた。

### ざっくり使い分け

| 用途 | 選択肢 |
|------|--------|
| 何でもやりたい | NVIDIA GPU |
| 超大規模モデルの学習 | Cerebras、Google TPU、AWS Trainium |
| 爆速で推論したい | Groq LPU |
| 省電力で推論し続けたい | Lenzo CGLA、AWS Inferentia |

### Groqについて補足

Groq LPUは「決定論的アーキテクチャ」で、GPUの2〜10倍のトークン生成速度を実現。

NVIDIAが2025年12月に200億ドルで買収した。「推論で勝てない」と判断して技術ごと買ったということ。

ちなみに、X社の「Grok」とは全くの別物（名前が似てるだけ）。

## まとめ

LFM 2.5から始まって、AI半導体の世界を覗いてみた。

**学んだこと：**
- NVIDIAの強さはGPU性能だけじゃない。CUDAエコシステムが本当の壁
- チップにはGPU→CGRA→CGLA→ASICという柔軟性/効率のスペクトラムがある
- 学習特化と推論特化で土俵が違う
- Groq LPUはNVIDIAが200億ドルで買収するほどの技術だった

そして調べていくうちに、NVIDIAの次世代アーキテクチャ「**Rubin**」に辿り着いた。Groqの技術を統合して、学習も推論も両方強化するらしい。

GPU一強時代はまだ続くのかもしれない。でも、挑戦者たちの「別の山を登る」戦略は面白い。

AI半導体の世界、もっと勉強していきたい。

## 参考リンク

- [NVIDIA を超える AI チップ Cerebras の全貌 - Zenn](https://zenn.dev/because02and/articles/cerebras-overview)
- [日本発AI半導体スタートアップ "Lenzo" - note](https://note.com/neo_tech_world/n/n547457d07c11)
- [Cerebras 公式](https://www.cerebras.ai/)
